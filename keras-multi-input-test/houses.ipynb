{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Data set pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_house_attributes(inputPath):\n",
    "    # initialize the list of column names in the CSV file and then\n",
    "    # load it using Pandas\n",
    "    \n",
    "    cols = [\"bedrooms\", \"bathrooms\", \"area\", \"zipcode\", \"price\"]\n",
    "    df = pd.read_csv(inputPath, sep=\" \", header=None, names=cols)\n",
    "    \n",
    "    # determine (1) the unique zip codes and (2) the number of data\n",
    "    # points with each zip code\n",
    "    zipcodes = df[\"zipcode\"].value_counts().keys().tolist()\n",
    "    counts = df[\"zipcode\"].value_counts().tolist()\n",
    "    \n",
    "    # loop over each of the unique zip codes and their corresponding\n",
    "    # count\n",
    "    for (zipcode, count) in zip(zipcodes, counts):\n",
    "        # the zip code counts for our housing dataset is *extremely*\n",
    "        # unbalanced (some only having 1 or 2 houses per zip code)\n",
    "        # so let's sanitize our data by removing any houses with less\n",
    "        # than 25 houses per zip code\n",
    "        if count < 25:\n",
    "            idxs = df[df[\"zipcode\"] == zipcode].index\n",
    "            df.drop(idxs, inplace=True)\n",
    "    \n",
    "    # return the data frame\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_house_attributes(df, train, test):\n",
    "    # initialize the column names of the continuous data\n",
    "    continuous = [\"bedrooms\", \"bathrooms\", \"area\"]\n",
    "    \n",
    "    # performin min-max scaling each continuous feature column to\n",
    "    # the range [0, 1]\n",
    "    cs = MinMaxScaler()\n",
    "    trainContinuous = cs.fit_transform(train[continuous])\n",
    "    testContinuous = cs.transform(test[continuous])\n",
    "    \n",
    "    # one-hot encode the zip code categorical data (by definition of\n",
    "    # one-hot encoding, all output features are now in the range [0, 1])\n",
    "    zipBinarizer = LabelBinarizer().fit(df[\"zipcode\"])\n",
    "    trainCategorical = zipBinarizer.transform(train[\"zipcode\"])\n",
    "    testCategorical = zipBinarizer.transform(test[\"zipcode\"])\n",
    "    \n",
    "    # construct our training and testing data points by concatenating\n",
    "    # the categorical features with the continuous features\n",
    "    trainX = np.hstack([trainCategorical, trainContinuous])\n",
    "    testX = np.hstack([testCategorical, testContinuous])\n",
    "    \n",
    "    # return the concatenated training and testing data\n",
    "    return (trainX, testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_house_images(df, inputPath):\n",
    "    # initialize our images array (i.e., the house images themselves)\n",
    "    images = []\n",
    "    \n",
    "    # loop over the indexes of the houses\n",
    "    for i in df.index.values:\n",
    "        # find the four images for the house and sort the file paths,\n",
    "        # ensuring the four are always in the *same order*\n",
    "        basePath = os.path.sep.join([inputPath, \"{}_*\".format(i + 1)])\n",
    "        housePaths = sorted(list(glob.glob(basePath)))\n",
    "        \n",
    "        # initialize our list of input images along with the output image\n",
    "        # after *combining* the four input images\n",
    "        inputImages = []\n",
    "        outputImage = np.zeros((64, 64, 3), dtype=\"uint8\")\n",
    "        \n",
    "        # loop over the input house paths\n",
    "        for housePath in housePaths:\n",
    "            # load the input image, resize it to be 32 32, and then\n",
    "            # update the list of input images\n",
    "            image = cv2.imread(housePath)\n",
    "            image = cv2.resize(image, (32, 32))\n",
    "            inputImages.append(image)\n",
    "        \n",
    "        # tile the four input images in the output image such the first\n",
    "        # image goes in the top-right corner, the second image in the\n",
    "        # top-left corner, the third image in the bottom-right corner,\n",
    "        # and the final image in the bottom-left corner\n",
    "        outputImage[0:32, 0:32] = inputImages[0]\n",
    "        outputImage[0:32, 32:64] = inputImages[1]\n",
    "        outputImage[32:64, 32:64] = inputImages[2]\n",
    "        outputImage[32:64, 0:32] = inputImages[3]\n",
    "        \n",
    "        # add the tiled image to our set of images the network will be\n",
    "        # trained on\n",
    "        images.append(outputImage)\n",
    "        \n",
    "    # return our set of images\n",
    "    return np.array(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
